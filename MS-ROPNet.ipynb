{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demographic Classification Using MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io, os,sys,types\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "from torch import autograd\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "import torch.utils.data\n",
    "\n",
    "import random\n",
    "import scipy.io\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import seaborn as sns\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import pretrainedmodels\n",
    "\n",
    "from pytorch_pretrained_vit import ViT\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from lion_pytorch import Lion\n",
    "import timm\n",
    "\n",
    "import nni\n",
    "from nni.experiment import Experiment\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/data/backupdata/backupdata/'\n",
    "model_dir = '/data/backupdata/backupdata/model_parameters/'\n",
    "\n",
    "Preandplus_input_categories = ['Aug_Preandplus_0_12_ROSE','Preandplus_0_12_ROSE', 'Preandplus_0_12_trainset',  'Preandplus_0_12_testset',\n",
    "                              'Aug_Preandplus_01_2_ROSE', 'Preandplus_01_2_ROSE', 'Preandplus_01_2_trainset',  'Preandplus_01_2_testset']\n",
    "\n",
    "# RWROP_input_categories = ['RWROP_image_demographic_ROSE', 'RWROP_image_demographic_trainset', 'RWROP_image_demographic_TKROSE', 'RWROP_setid_image_demographic_testset']\n",
    "\n",
    "RWROP_input_categories = ['RWROP_image_demographic_trainROSE','RWROP_image_demographic_trainROSEE1', 'RWROP_image_demographic_trainset', 'RWROP_image_demographic_valset', 'RWROP_setid_image_demographic_testset']\n",
    "\n",
    "Preandplus_categories = ['preandplus_0', 'preandplus_1']\n",
    "RWROP_categories = ['RWROP_0', 'RWROP_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'model1_name' : 'ViT',\n",
    "    'model2_name' : 'vgg19_bn',\n",
    "    'preandplus_traindata_dir': '/data/eye_image/fold_0/Aug_stage_ROSE',\n",
    "    'preandplus_valdata_dir': '/data/eye_image/fold_0/stage_testset',\n",
    "    'preandplus_testdata_dir': '/data/eye_image/fold_0/stage_testset',\n",
    "    'stage_traindata_dir': '/data/eye_image/fold_0/Aug_plus_ROSE',\n",
    "    'stage_valdata_dir': '/data/eye_image/fold_0/plus_testset',\n",
    "    'stage_testdata_dir': '/data/eye_image/fold_0/plus_testset',\n",
    "    'stage3ROP_traindata_dir': '/data/eye_image/fold_0/Aug_Zone1_ROSE',\n",
    "    'stage3ROP_valdata_dir': '/data/eye_image/fold_0/Zone1_testset',\n",
    "    'stage3ROP_testdata_dir': '/data/eye_image/fold_0/Zone1_testset',\n",
    "    'Zone1ROP_traindata_dir': '/data/eye_image/fold_4/Aug_rw_ROSE',\n",
    "    'Zone1ROP_valdata_dir': '/data/eye_image/fold_4/rw_testset',\n",
    "    'Zone1ROP_testdata_dir': '/data/eye_image/fold_4/rw_testset',\n",
    "    'RWROP_traindata_dir': '/data/eye_image/fold_4/Aug_rw_ROSE',\n",
    "    'RWROP_valdata_dir': '/data/eye_image/fold_4/rw_testset',\n",
    "    'RWROP_testdata_dir': '/data/eye_image/fold_4/rw_testset',\n",
    "    'train_batch_size': [16,16,16,16,16], \n",
    "    'val_batch_size': 64,\n",
    "    'test_batch_size': 32,\n",
    "    'num_epochs': 120,\n",
    "    'warm_up_epoch': 5,\n",
    "    'patient_epoch': 60,\n",
    "    'h_lr': 0.0001,\n",
    "    'l_lr': 0.00002,\n",
    "    'initial_lr': 0.00001,\n",
    "    'learning_rate': 0.0001,\n",
    "    'S_S_GAP': [0.4,0.4,0.4,0.4,0.4],\n",
    "    'w_momentum': 0.9,\n",
    "    'w_weight_decay': 0.0001,\n",
    "    'workers': 4,\n",
    "    'seed': 42,\n",
    "    'alpha': 0.55,\n",
    "    'gamma': 1,\n",
    "    'loss-weight': [torch.tensor([1.15,1.85], dtype=torch.float32),torch.tensor([1.15,1.85], dtype=torch.float32),\n",
    "                   torch.tensor([1.15,1.85], dtype=torch.float32),torch.tensor([1.15,1.85], dtype=torch.float32),\n",
    "                   torch.tensor([1.15,1.85], dtype=torch.float32)],\n",
    "    'aucthreshold': 0.95,\n",
    "    'aucboosting': 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG-ST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGGA_ST_stage(nn.Module):\n",
    "    def __init__(self, VGG19, ST, hidden_dim=512, n_layers=2, dropout=0.5):\n",
    "        super(VGGA_ST_stage, self).__init__()\n",
    "        self.vgg_transform = transforms.Compose([transforms.Resize((224,224))])\n",
    "        self.vgg19_backbone = nn.Sequential(*list(VGG19.children())[1:-7])\n",
    "        ST.flatten = nn.GELU()\n",
    "        self.ST_backbone = ST\n",
    "        self.MP = nn.MaxPool1d(4)\n",
    "        self.vgg_linear3 = nn.Linear(6272,6272)\n",
    "        self.vgg_linear4 = nn.Linear(6272,2048)\n",
    "        self.vgg_linear5 = nn.Linear(2048,512)\n",
    "        self.vgg_linear6 = nn.Linear(512,2)\n",
    "        self.vgg_relu2 = nn.GELU()\n",
    "        self.vgg_relu3 = nn.GELU()\n",
    "        self.vgg_relu4 = nn.GELU()\n",
    "        self.st_linear1 = nn.Linear(1024,1024)\n",
    "        self.st_relu1 = nn.GELU()\n",
    "        self.st_linear2 = nn.Linear(1024,2)\n",
    "\n",
    "        layers = []\n",
    "        for i in range(n_layers):\n",
    "            layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            layers.append(nn.GELU())\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "        layers.append(nn.Linear(hidden_dim, 2))\n",
    "        self.mlp_layers = nn.Sequential(*layers)\n",
    "\n",
    "        \n",
    "        self.linear1 = nn.Linear(1536,hidden_dim)\n",
    "        self.relu1 = nn.GELU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "        \n",
    "#         ViT.fc = nn.Linear(768,768)\n",
    "#         nn.init.xavier_uniform(model.fc.weight)\n",
    "#         self.ViT_feature_layer = model\n",
    "#         self.relu1 = nn.ReLU()\n",
    "#         self.linear1 = nn.Linear(768,2)\n",
    "#         nn.init.xavier_uniform(self.linear1.weight)\n",
    "#         self.softmax = nn.Softmax(dim=1)\n",
    "    def resize_img_size(self, x):\n",
    "        for img_idx in range(x.shape[0]):\n",
    "            if img_idx == 0:\n",
    "                y = self.vgg_transform(x[img_idx]).unsqueeze(0)\n",
    "            else:\n",
    "                y = torch.cat((y, self.vgg_transform(x[img_idx]).unsqueeze(0)),0)\n",
    "        return y\n",
    " \n",
    "    \n",
    "    def forward(self, x):\n",
    "        vgg_output = self.vgg19_backbone(self.resize_img_size(x))\n",
    "        vgg_output = vgg_output.view(vgg_output.shape[0],-1)\n",
    "        vgg_output = self.MP(vgg_output)\n",
    "        vgg_output = self.vgg_linear3(vgg_output)\n",
    "        vgg_output = self.vgg_relu2(vgg_output)\n",
    "        vgg_output = self.vgg_linear4(vgg_output)\n",
    "        vgg_output = self.vgg_relu3(vgg_output)\n",
    "        vgg_output = self.vgg_linear5(vgg_output)\n",
    "        vgg_output = self.vgg_relu4(vgg_output)\n",
    "        vgg_output1 = self.vgg_linear6(vgg_output)\n",
    "        # vgg_output1 = self.vgg_softmax(vgg_output1)\n",
    "        st_output = self.ST_backbone(x)\n",
    "        st_output = self.st_linear1(st_output)\n",
    "        st_output = self.st_relu1(st_output)\n",
    "        st_output1 = self.st_linear2(st_output)\n",
    "        # st_output1 = self.st_softmax(st_output1)\n",
    "        \n",
    "        output = torch.cat((vgg_output, st_output),1)\n",
    "        output = self.linear1(output)\n",
    "        output = self.relu1(output)\n",
    "        logits = self.mlp_layers(output)\n",
    "        probs = self.softmax(logits)\n",
    "\n",
    "        return logits, vgg_output1, st_output1, probs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# three loss\n",
    "def train(model, loss_fn, optimizer, scheduler, param, folder_index, loader_train, loader_val, modal_dir):\n",
    "\n",
    "    model.train()\n",
    "    max_auc = 0\n",
    "\n",
    "    best_epopch = 0\n",
    "    patient_epoch = 0\n",
    "    for epoch in range(param['num_epochs']):\n",
    "        model.train()\n",
    "        print('Starting epoch %d / %d' % (epoch + 1, param['num_epochs']))\n",
    "    #         adjust_learning_rate(optimizer, epoch)\n",
    "        epoch_loss = 0\n",
    "        with torch.enable_grad():\n",
    "            for t, (x, y) in enumerate(loader_train):\n",
    "\n",
    "                x_var, y_var = x.to(device), y.to(device)\n",
    "                _, scores, scores_resnet, scores_st = model(x_var)\n",
    "                loss_m = loss_fn(scores, y_var)\n",
    "                loss_r = loss_fn(scores_resnet, y_var)\n",
    "                loss_st = loss_fn(scores_st, y_var)\n",
    "                loss = param['3lossw'][0]*loss_m + param['3lossw'][1]*loss_r + param['3lossw'][2]*loss_st\n",
    "                epoch_loss += loss.item()\n",
    "                \n",
    "\n",
    "                if (t + 1) % 100 == 0:\n",
    "                    #print(loss.item())\n",
    "                    print('t = %d, loss = %.8f' % (t + 1, loss.item()))\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "        #             nn.utils.clip_grad_norm_(model.parameters(), config['w_grad_clip'])\n",
    "                optimizer.step()\n",
    "        # # --- Record training loss ---\n",
    "        # writer.add_scalar('Loss/Train', epoch_loss, epoch)\n",
    "        # # --- Record lr ---\n",
    "        # current_lr = optimizer.param_groups[0]['lr']\n",
    "        # writer.add_scalar('Learning Rate', current_lr, epoch)\n",
    "        # # --- Record Gradient Norms ---\n",
    "        # total_norm = 0.0\n",
    "        # for p in model.parameters():\n",
    "        #     if p.grad is not None:  # Ensure gradients exist\n",
    "        #         param_norm = p.grad.data.norm(2)  # Compute L2 norm\n",
    "        #         total_norm += param_norm.item() ** 2\n",
    "        # total_norm = total_norm ** 0.5  # Square root of the sum of squares\n",
    "        # writer.add_scalar('Gradient Norm', total_norm, epoch)\n",
    "\n",
    "        # # --- Record Model Weights and Biases ---\n",
    "        # for name, p in model.named_parameters():\n",
    "        #     writer.add_histogram(f'Params/{name}', p, epoch)  # Log weights/biases\n",
    "        #     if p.grad is not None:\n",
    "        #         writer.add_histogram(f'Gradients/{name}', p.grad, epoch)  # Log gradients\n",
    "\n",
    "        model.eval()\n",
    "        epoch_auc = validate(model, loader_val, param['S_S_GAP'][folder_index])\n",
    "        patient_epoch = patient_epoch + 1\n",
    "        with torch.enable_grad():\n",
    "            if epoch_auc > max_auc:\n",
    "                max_auc = epoch_auc\n",
    "                best_epopch = epoch\n",
    "                torch.save(model.state_dict(), modal_dir)\n",
    "                patient_epoch = 0\n",
    "            scheduler.step(max_auc)\n",
    "\n",
    "        if patient_epoch > param['patient_epoch']:\n",
    "            print('reach patient epoch')\n",
    "            break\n",
    "    return max_auc     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, loader, gap):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        test_batch_index = 0\n",
    "        for x, y in loader:\n",
    "\n",
    "            x_var = x.to(device)\n",
    "            scores, _, _, _ = model(x_var)\n",
    "            _, preds = scores.data.cpu().max(1)\n",
    "            if test_batch_index == 0:\n",
    "                y_test = y.cpu().detach().numpy()\n",
    "                y_probs = scores.cpu().detach().numpy()\n",
    "                y_pred = preds.numpy()\n",
    "            else:\n",
    "                y_test = np.append(y_test, y.cpu().detach().numpy())\n",
    "                y_probs = np.vstack((y_probs, scores.cpu().detach().numpy()))\n",
    "                y_pred = np.append(y_pred, preds.cpu().detach().numpy())\n",
    "\n",
    "            test_batch_index += 1\n",
    "\n",
    "        # print(y_test.shape)\n",
    "        y_probs = y_probs[...,1:]\n",
    "        # print(y_probs.shape)\n",
    "        # print(y_pred.shape)\n",
    "    #     test_prob_dir = './data/eye_image/fold_0/Resnet_Aug_rwROSE_test_prob.txt'\n",
    "    #     np.savetxt(test_prob_dir, y_probs ,fmt='%.10e', delimiter=\" \") \n",
    "    #     np.savetxt(test_label_dir, y_test ,fmt='%.10e', delimiter=\" \")\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        specificity = tn / (tn + fp)\n",
    "        AUC_score = roc_auc_score(y_test, y_probs, multi_class='ovr')\n",
    "        # f1 = f1_score(y_test, y_pred)\n",
    "        # accuracy = accuracy_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        # precision = precision_score(y_test, y_pred)\n",
    "        print('AUC_score:', AUC_score)\n",
    "        print('recall:', recall)\n",
    "        print('specificity:', specificity)\n",
    "\n",
    "        # writer.add_scalar('AUC/Val', AUC_score, epoch)\n",
    "        # writer.add_scalar('Sensitivity/Val', recall, epoch)\n",
    "        # writer.add_scalar('Specificity/Val', specificity, epoch)\n",
    "        # writer.add_scalar('F1/Val', f1, epoch)\n",
    "        # writer.add_scalar('precision/Val', precision, epoch)\n",
    "        # writer.add_scalar('accuracy/Val', accuracy, epoch)\n",
    "        \n",
    "        if abs(recall - specificity) >= gap:\n",
    "            return 0\n",
    "        else:\n",
    "            return AUC_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, loader, test_prob_dir, test_label_dir):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "    \n",
    "        for name, parameters in model.named_parameters():\n",
    "            parameters.requires_grad = False\n",
    "\n",
    "        num_correct, num_samples = 0, len(loader.dataset)\n",
    "\n",
    "        test_batch_index = 0\n",
    "\n",
    "        for x, y in loader:\n",
    "\n",
    "            x_var = x.to(device)\n",
    "            scores, _, _, _ = model(x_var)\n",
    "            _, preds = scores.data.cpu().max(1)\n",
    "            if test_batch_index == 0:\n",
    "                y_test = y.cpu().detach().numpy()\n",
    "                y_probs = scores.cpu().detach().numpy()\n",
    "                y_pred = preds.numpy()\n",
    "            else:\n",
    "                y_test = np.append(y_test, y.cpu().detach().numpy())\n",
    "                y_probs = np.vstack((y_probs, scores.cpu().detach().numpy()))\n",
    "                y_pred = np.append(y_pred, preds.cpu().detach().numpy())\n",
    "\n",
    "            num_correct += (preds == y).sum()\n",
    "            test_batch_index += 1\n",
    "\n",
    "        acc = float(num_correct) / num_samples\n",
    "        # print(y_test.shape)\n",
    "        y_probs = y_probs[...,1:]\n",
    "        # print(y_probs.shape)\n",
    "        # print(y_pred.shape)\n",
    "    #     test_prob_dir = './data/eye_image/fold_0/Resnet_Aug_rwROSE_test_prob.txt'\n",
    "        np.savetxt(test_prob_dir, y_probs ,fmt='%.10e', delimiter=\" \") \n",
    "        np.savetxt(test_label_dir, y_test ,fmt='%.10e', delimiter=\" \")\n",
    "\n",
    "        print('Test accuracy: {:.2f}% ({}/{})'.format(\n",
    "            100.*acc,\n",
    "            num_correct,\n",
    "            num_samples,\n",
    "            ))\n",
    "\n",
    "        AUC_score = roc_auc_score(y_test, y_probs, multi_class='ovr')\n",
    "        AUPRC_score = average_precision_score(y_test, y_probs)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "#         sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "\n",
    "        \n",
    "        print('AUC:')\n",
    "        print(AUC_score)\n",
    "        print('AUPRC:')\n",
    "        print(AUPRC_score)\n",
    "        print('recall:')\n",
    "        print(recall)\n",
    "        print('specificity:')\n",
    "        print(specificity)\n",
    "        print('F1:')\n",
    "        print(f1)\n",
    "        print('precision:')\n",
    "        print(precision)\n",
    "        print('Accuracy:')\n",
    "        print(accuracy)\n",
    "\n",
    "    return AUC_score, AUPRC_score, recall, specificity, f1, precision, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, npz_file, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            npz_file (str): Path to the .npz file containing labels, demographic data, and file names.\n",
    "            image_dir (str): Directory where the images are stored.\n",
    "            transform (callable, optional): Transform to be applied to the images.\n",
    "        \"\"\"\n",
    "        # Load the .npz file\n",
    "        data = np.load(npz_file, allow_pickle=True)\n",
    "        self.labels = data['label']\n",
    "        self.demographics = data['demographic']\n",
    "        self.file_names = data['file_name']\n",
    "        self.image_dir = os.path.dirname(npz_file)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_dir = os.path.join(self.image_dir, os.path.basename(self.file_names[idx]))\n",
    "        image = Image.open(img_dir).convert('RGB')\n",
    "\n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Get demographic data and label\n",
    "        # demographic = torch.tensor(self.demographics[idx], dtype=torch.float32)\n",
    "        label = torch.tensor(int(self.labels[idx]), dtype=torch.long)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_AUC = []\n",
    "fold_AUPRC = []\n",
    "fold_Recall = []\n",
    "fold_Specificity = []\n",
    "fold_F1 = []\n",
    "fold_Precision = []\n",
    "fold_Accuracy = []\n",
    "for i in range(5):\n",
    "    param['RWROP_traindata_dir'] = os.path.join(root_dir, 'fold_'+ str(i), RWROP_input_categories[0],'RWROP_filename_image_demographic_trainROSE.npz')\n",
    "    param['RWROP_valdata_dir'] = os.path.join(root_dir, 'fold_'+ str(i), RWROP_input_categories[2],'RWROP_filename_image_demographic_valset.npz')\n",
    "    param['RWROP_testdata_dir'] = os.path.join(root_dir, 'fold_'+ str(i), RWROP_input_categories[3],'RWROP_filename_image_demographic_testset.npz')\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        CustomDataset(param['RWROP_traindata_dir'], transforms.Compose([\n",
    "            transforms.Resize((256,256)),\n",
    "            transforms.RandomRotation(30),\n",
    "            transforms.RandomVerticalFlip(0.2),\n",
    "            transforms.RandomHorizontalFlip(0.2),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])),\n",
    "        batch_size=param['train_batch_size'], shuffle=True,\n",
    "        num_workers=param['workers'], pin_memory=True)\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        CustomDataset(param['RWROP_valdata_dir'], transforms.Compose([\n",
    "            transforms.Resize((256,256)),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])),\n",
    "        batch_size=param['val_batch_size'], shuffle=False,\n",
    "        num_workers=param['workers'], pin_memory=True)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        CustomDataset(param['RWROP_testdata_dir'], transforms.Compose([\n",
    "            transforms.Resize((256,256)),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])),\n",
    "        batch_size=param['test_batch_size'], shuffle=False,\n",
    "        num_workers=param['workers'], pin_memory=True)\n",
    "    \n",
    "    vgg19_bn = pretrainedmodels.__dict__[param['model2_name']](num_classes=1000, pretrained='imagenet')\n",
    "    swin_t = timm.create_model( 'swinv2_base_window16_256' , pretrained= True , num_classes=1024)\n",
    "    model = VGG_ST(vgg19_bn, swin_t, hidden_dim=512, n_layers=2, dropout=0.5)\n",
    "    model.to(device)\n",
    "\n",
    "    for name, parameters in model.named_parameters():\n",
    "        if \"ST_backbone\" in name:\n",
    "            parameters.requires_grad = False\n",
    "    for name, parameters in model.named_parameters():\n",
    "        if \"ST_backbone.head.fc\" in name:\n",
    "            parameters.requires_grad = True\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(weight=param['loss-weight'][i].to(device))\n",
    "    optimizer = torch.optim.Adam(filter(lambda p:p.requires_grad, model.parameters()), lr=param['learning_rate'], weight_decay=param['w_weight_decay'])\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5,threshold=1e-5, threshold_mode='abs', patience=10, min_lr=param['initial_lr'])\n",
    "    net_dir = os.path.join(model_dir, 'VGG-ST-512'+ 'fold_'+ str(i) + RWROP_input_categories[0]+'_raw_RWROP_model_parameter1.pkl')\n",
    "    if os.path.exists(net_dir):\n",
    "        os.remove(net_dir)\n",
    "    best_auc = train(model, criterion, optimizer, scheduler, param, i, train_loader, val_loader, net_dir)\n",
    "    model.load_state_dict(torch.load(net_dir))\n",
    "    test_prob_dir = os.path.join(root_dir, 'fold_'+ str(i), 'VGG-ST-512'+RWROP_input_categories[0]+'_raw_RWROP_test_prob.txt')\n",
    "    test_label_dir = os.path.join(root_dir, 'fold_'+ str(i), 'VGG-ST-512'+RWROP_input_categories[0]+'_raw_RWROP_test_label.txt')\n",
    "    AUC_score, AUPRC_score, recall, specificity, f1, precision, accuracy = test(model, test_loader, test_prob_dir, test_label_dir)\n",
    "    fold_AUC.append(AUC_score)\n",
    "    fold_AUPRC.append(AUPRC_score)\n",
    "    fold_Recall.append(recall)\n",
    "    fold_Specificity.append(specificity)\n",
    "    fold_F1.append(f1)\n",
    "    fold_Precision.append(precision)\n",
    "    fold_Accuracy.append(accuracy)\n",
    "assert len(fold_AUC) == len(fold_AUPRC) == len(fold_Recall) == len(fold_Specificity) == len(fold_F1) == len(fold_Precision) == len(fold_Accuracy) == 5\n",
    "AUC_result = np.array(fold_AUC)\n",
    "AUPRC_result = np.array(fold_AUPRC)\n",
    "F1_result = np.array(fold_F1)\n",
    "Accuracy_result = np.array(fold_Accuracy)\n",
    "Recall_result = np.array(fold_Recall)\n",
    "Precision_result = np.array(fold_Precision)\n",
    "# Sensitivity_result = np.array(fold_Sensitivity)\n",
    "Specificity_result = np.array(fold_Specificity)\n",
    "\n",
    "print('AUC_result')\n",
    "print(AUC_result)\n",
    "print('AUPRC_result')\n",
    "print(AUPRC_result)\n",
    "print('Recall_result')\n",
    "print(Recall_result)\n",
    "print('Specificity_result')\n",
    "print(Specificity_result)\n",
    "print('F1_result')\n",
    "print(F1_result)\n",
    "print('Precision_result')\n",
    "print(Precision_result)\n",
    "print('Accuracy_result')\n",
    "print(Accuracy_result)\n",
    "\n",
    "\n",
    "# print('Sensitivity_result')\n",
    "# print(Sensitivity_result)\n",
    "\n",
    "\n",
    "print('Avg_AUC:')\n",
    "print(np.mean(AUC_result))\n",
    "print('std_AUC:')\n",
    "print(np.std(AUC_result))\n",
    "\n",
    "print('Avg_AUPRC:')\n",
    "print(np.mean(AUPRC_result))\n",
    "print('std_AUPRC:')\n",
    "print(np.std(AUPRC_result))\n",
    "\n",
    "print('Avg_Recall:')\n",
    "print(np.mean(Recall_result))\n",
    "print('std_Recall:')\n",
    "print(np.std(Recall_result))\n",
    "\n",
    "print('Avg_Specificity:')\n",
    "print(np.mean(Specificity_result))\n",
    "print('std_Specificity:')\n",
    "print(np.std(Specificity_result))\n",
    "\n",
    "print('Avg_F1:')\n",
    "print(np.mean(F1_result))\n",
    "print('std_F1:')\n",
    "print(np.std(F1_result))\n",
    "\n",
    "print('Avg_Precision:')\n",
    "print(np.mean(Precision_result))\n",
    "print('std_Precision:')\n",
    "print(np.std(Precision_result))\n",
    "\n",
    "print('Avg_Accuracy:')\n",
    "print(np.mean(Accuracy_result))\n",
    "print('std_Accuracy:')\n",
    "print(np.std(Accuracy_result))\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_feature_dim_list = [5,16,32,64,128,256]\n",
    "n_estimators_list = [200,300,400,500]\n",
    "max_depth_list = [None]\n",
    "min_samples_split_list = [2, 3, 5]\n",
    "min_samples_leaf_list = [1, 2, 3]\n",
    "max_features_list = ['sqrt', 'log2', None]\n",
    "class_weight_list = [{0: 1, 1: 1},{0: 1, 1: 2}, {0: 1, 1: 3}, {0: 1, 1: 4}]\n",
    "auc_list = []\n",
    "recall_list = []\n",
    "specificity_list = []\n",
    "f1_list = []\n",
    "precision_list = []\n",
    "accuracy_list = []\n",
    "\n",
    "best_setting_result = {'fold_0': None, 'fold_1': None, 'fold_2': None, 'fold_3': None, 'fold_4': None}\n",
    "for i in range(5):\n",
    "    max_auc = 0\n",
    "    pbar = tqdm(total=len(image_feature_dim_list) * len(n_estimators_list) * len(max_depth_list) * len(min_samples_split_list) * len(min_samples_leaf_list) * len(max_features_list) * len(class_weight_list), desc=f\"Processing fold {i}\")\n",
    "    for image_feature_dim in image_feature_dim_list:\n",
    "        param['RWROP_traindata_dir'] = os.path.join(root_dir, 'fold_'+ str(i), 'VGG-ST-'+str(image_feature_dim)+'-demograhpic'+RWROP_input_categories[0]+'_features.npz')\n",
    "        param['RWROP_valdata_dir'] = os.path.join(root_dir, 'fold_'+ str(i), 'VGG-ST-'+str(image_feature_dim)+'-demograhpic'+RWROP_input_categories[3]+'_features.npz')\n",
    "        train_data = np.load(param['RWROP_traindata_dir'], allow_pickle=True)\n",
    "        val_data = np.load(param['RWROP_valdata_dir'], allow_pickle=True)\n",
    "        train_demographic = train_data['demographic_features'][:, :5]\n",
    "        train_label = train_data['label'].astype(int)\n",
    "        val_demographic = val_data['demographic_features'][:, :5]\n",
    "        val_image_probs = val_data['image_probs']\n",
    "        val_label = val_data['label'].astype(int)\n",
    "        for n_estimators in n_estimators_list:\n",
    "            for max_depth in max_depth_list:\n",
    "                for min_samples_split in min_samples_split_list:\n",
    "                    for min_samples_leaf in min_samples_leaf_list:\n",
    "                        for max_features in max_features_list:\n",
    "                            for class_weight in class_weight_list:\n",
    "                                rf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, min_samples_split=min_samples_split,\n",
    "                                                       min_samples_leaf=min_samples_leaf, max_features=max_features, class_weight=class_weight, random_state=42)\n",
    "                                rf.fit(train_demographic,train_label)\n",
    "                                y_proba = rf.predict_proba(val_demographic)\n",
    "                                y_proba_class_1 = y_proba[:, 1]\n",
    "                                y_proba_class_1 = (y_proba_class_1 + val_image_probs) / 2\n",
    "                                AUC_score = roc_auc_score(val_label, y_proba_class_1, multi_class='ovr')\n",
    "                                pbar.update(1)\n",
    "                                if AUC_score > max_auc:\n",
    "                                    max_auc = AUC_score\n",
    "                                    best_setting = {'image_feature_dim': image_feature_dim, 'n_estimators': n_estimators, 'max_depth': max_depth, 'min_samples_split': min_samples_split,\n",
    "                                                      'min_samples_leaf': min_samples_leaf, 'max_features': max_features, 'class_weight': class_weight}\n",
    "    pbar.close()\n",
    "    param['RWROP_traindata_dir'] = os.path.join(root_dir, 'fold_'+ str(i), 'VGG-ST-'+str(best_setting['image_feature_dim'])+'-demograhpic'+RWROP_input_categories[0]+'_features.npz')\n",
    "    param['RWROP_testdata_dir'] = os.path.join(root_dir, 'fold_'+ str(i), 'VGG-ST-'+str(best_setting['image_feature_dim'])+'-demograhpic'+RWROP_input_categories[4]+'_features.npz')\n",
    "    train_data = np.load(param['RWROP_traindata_dir'], allow_pickle=True)\n",
    "    test_data = np.load(param['RWROP_testdata_dir'], allow_pickle=True)\n",
    "    train_demographic = train_data['demographic_features'][:, :5]\n",
    "    train_label = train_data['label'].astype(int)\n",
    "    test_demographic = test_data['demographic_features'][:, :5]\n",
    "    test_image_probs = test_data['image_probs']\n",
    "    test_label = test_data['label']\n",
    "    rf = RandomForestClassifier(n_estimators=best_setting['n_estimators'], max_depth=best_setting['max_depth'], min_samples_split=best_setting['min_samples_split'],\n",
    "                               min_samples_leaf=best_setting['min_samples_leaf'], max_features=best_setting['max_features'], class_weight=best_setting['class_weight'], random_state=42)\n",
    "    rf.fit(train_demographic,train_label)\n",
    "    y_proba = rf.predict_proba(test_demographic)\n",
    "    y_proba_class_1 = y_proba[:, 1]\n",
    "    y_proba_class_1 = (y_proba_class_1 + test_image_probs) / 2\n",
    "    AUC_score = roc_auc_score(test_label, y_proba_class_1, multi_class='ovr')\n",
    "    y_pred_rf = np.where(y_proba_class_1 >= 0.5, 1, 0)\n",
    "    f1 = f1_score(test_label, y_pred_rf)\n",
    "    accuracy = accuracy_score(test_label, y_pred_rf)\n",
    "    recall = recall_score(test_label, y_pred_rf)\n",
    "    precision = precision_score(test_label, y_pred_rf)\n",
    "    tn, fp, fn, tp = confusion_matrix(test_label, y_pred_rf).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    auc_list.append(AUC_score)\n",
    "    f1_list.append(f1)\n",
    "    accuracy_list.append(accuracy)\n",
    "    recall_list.append(recall)\n",
    "    precision_list.append(precision)\n",
    "    specificity_list.append(specificity)\n",
    "    best_setting_result['fold_'+ str(i)] = {'image_feature_dim': best_setting['image_feature_dim'], 'n_estimators': best_setting['n_estimators'], 'max_depth': best_setting['max_depth'], 'min_samples_split': best_setting['min_samples_split'],\n",
    "                          'min_samples_leaf': best_setting['min_samples_leaf'], 'max_features': best_setting['max_features'], 'class_weight': best_setting['class_weight'],\n",
    "                          'AUC': AUC_score, 'Recall': recall, 'Specificity': specificity, 'F1': f1, 'Precision': precision, 'Accuracy': accuracy}\n",
    "\n",
    "assert len(auc_list) == len(f1_list) == len(accuracy_list) == len(recall_list) == len(precision_list) == len(specificity_list) == 5\n",
    "np_auc = np.array(auc_list)\n",
    "np_f1 = np.array(f1_list)\n",
    "np_accuracy = np.array(accuracy_list)\n",
    "np_recall = np.array(recall_list)\n",
    "np_precision = np.array(precision_list)\n",
    "np_specificity = np.array(specificity_list)\n",
    "print('Average AUC: ', np.mean(np_auc))\n",
    "print('std AUC: ', np.std(np_auc))\n",
    "print('Average recall: ', np.mean(np_recall))\n",
    "print('std recall: ', np.std(np_recall))\n",
    "print('Average specificity: ', np.mean(np_specificity))\n",
    "print('std specificity: ', np.std(np_specificity))\n",
    "print('Average F1: ', np.mean(np_f1))\n",
    "print('std F1: ', np.std(np_f1))\n",
    "print('Average precision: ', np.mean(np_precision))\n",
    "print('std precision: ', np.std(np_precision))\n",
    "print('Average accuracy: ', np.mean(np_accuracy))\n",
    "print('std accuracy: ', np.std(np_accuracy))\n",
    "print(best_setting_result)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
